{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text,tokenizer,model,is_split_into_words=True):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", is_split_into_words=is_split_into_words)\n",
    "    labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(**inputs, labels=labels)\n",
    "    output = np.array(outputs.hidden_states[12][0].tolist())\n",
    "    return output\n",
    "\n",
    "    # back to torch tensor:\n",
    "    # torch.from_numpy(output).float()\n",
    "    \n",
    "def ht_lr(train_features, train_labels, test_features):\n",
    "    # aligning target domain to source domain\n",
    "    lr_clf = LogisticRegression(max_iter = 10000)\n",
    "    lr_clf.fit(train_features, train_labels)\n",
    "    y_pred = lr_clf.predict(test_features)\n",
    "    y_prob = lr_clf.predict_proba(test_features)[:, 0]\n",
    "    y_prob = [(i, val, y_pred[i]) for i, val in enumerate(y_prob)]\n",
    "    y_prob = sorted(y_prob, key=lambda x: x[1])\n",
    "    y_prob_P = y_prob[:int(len(test_features) / 10)]\n",
    "    y_prob_N = y_prob[-int(len(test_features) / 10):]\n",
    "\n",
    "    sourcePos = [val for i, val in enumerate(train_features) if train_labels[i] == 1]\n",
    "    sourceNeg = [val for i, val in enumerate(train_features) if train_labels[i] == 0]\n",
    "    targetPos = [test_features[val[0]] for val in y_prob_P]\n",
    "    targetNeg = [test_features[val[0]] for val in y_prob_N]\n",
    "    v = np.mean(sourcePos, axis=0) - np.mean(sourceNeg, axis=0)\n",
    "    u = np.mean(targetPos, axis=0) - np.mean(targetNeg, axis=0)\n",
    "    c1 = np.mean(test_features, axis=0)\n",
    "    c2 = np.mean(np.concatenate([sourcePos, sourceNeg], axis=0), axis=0)\n",
    "\n",
    "    test_features = hh_lr(u, v, c1, c2, test_features)\n",
    "    return test_features\n",
    "\n",
    "\n",
    "def hh_lr(u, v, c1, c2, points):\n",
    "    # household transformation\n",
    "    u_mag = np.linalg.norm(u)\n",
    "    u_unit = u / u_mag\n",
    "\n",
    "    v_mag = np.linalg.norm(v)\n",
    "    v_unit = v / v_mag\n",
    "\n",
    "    # Scaling so pos-neg vectors have the same magnitude\n",
    "    scaled_points = points * v_mag / u_mag\n",
    "    scaled_c1 = c1 * v_mag / u_mag\n",
    "\n",
    "    # gettinng dimension of vector space\n",
    "    k = len(c2)\n",
    "\n",
    "    # calculating isometric linear transformation: householder transformation\n",
    "    A = np.eye(k) - (2 * (np.outer(u_unit - v_unit, u_unit - v_unit) / np.inner(u_unit - v_unit, u_unit - v_unit)))\n",
    "\n",
    "    # applying isometric transformation\n",
    "    points_after_isometric = scaled_points @ A.T\n",
    "    c1_after_isometric = scaled_c1 @ A.T\n",
    "\n",
    "    # translation\n",
    "    points_after_translation = points_after_isometric + (c2 - c1_after_isometric)\n",
    "\n",
    "    return points_after_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoNLL2003 pretrained BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT example\n",
    "inputs = tokenizer(\"embedding is good\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits \n",
    "# equal to model.classifier(outputs.hidden_states[12]) \n",
    "# equal to model.classifier(torch.from_numpy(get_embedding(\"Hello, my dog is cute\",tokenizer,model,is_split_into_words=False)).float()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'em', '##bed', '##ding', 'is', 'good', '[SEP]']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (C:\\Users\\zhw027\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    }
   ],
   "source": [
    "# load CoNLL2003\n",
    "datasets = load_dataset(\"conll2003\")\n",
    "label_list = datasets[\"train\"].features[f\"{'ner'}_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'id': '0',\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_tags_train = [[label_list[i] for i in dict['ner_tags']] for dict in datasets[\"train\"]]\n",
    "conll_tags_val = [[label_list[i] for i in dict['ner_tags']] for dict in datasets[\"validation\"]]\n",
    "conll_tags_test = [[label_list[i] for i in dict['ner_tags']] for dict in datasets[\"test\"]]\n",
    "\n",
    "conll_tokens_train = [dict['tokens'] for dict in datasets[\"train\"]]\n",
    "conll_tokens_val = [dict['tokens'] for dict in datasets[\"validation\"]]\n",
    "conll_tokens_test = [dict['tokens'] for dict in datasets[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n"
     ]
    }
   ],
   "source": [
    "conll_emb_train = []\n",
    "for i,token in enumerate(conll_tokens_train):\n",
    "    conll_emb_train.append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "conll_emb_val = []\n",
    "for i,token in enumerate(conll_tokens_val):\n",
    "    conll_emb_val.append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "conll_emb_test = []\n",
    "for i,token in enumerate(conll_tokens_test):\n",
    "    conll_emb_test.append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll = {}\n",
    "conll['train'] = {}\n",
    "conll['train']['tokens'] = conll_tokens_train\n",
    "conll['train']['tags'] = conll_tags_train\n",
    "conll['train']['emb'] = conll_emb_train\n",
    "conll['val'] = {}\n",
    "conll['val']['tokens'] = conll_tokens_val\n",
    "conll['val']['tags'] = conll_tags_val\n",
    "conll['val']['emb'] = conll_emb_val\n",
    "conll['test'] = {}\n",
    "conll['test']['tokens'] = conll_tokens_test\n",
    "conll['test']['tags'] = conll_tags_test\n",
    "conll['test']['emb'] = conll_emb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save pickle\n",
    "with open(\"../data/ner/CoNLL2003.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(conll, fw)\n",
    "\n",
    "# ## Load pickle\n",
    "# with open(\"../data/ner/CoNLL2003.pickle\",\"rb\") as fr:\n",
    "#     conll = pickle.load(fr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load tech_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300677"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([y for x in conll['train']['emb'] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_test = {}\n",
    "tech_test['test'] = {}\n",
    "tech_test['test']['tokens'] = []\n",
    "tech_test['test']['tags'] = []\n",
    "tech_test['test']['emb'] = []\n",
    "\n",
    "with open('../data/ner/tech_test.txt', 'r') as f:\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for line in f.readlines():\n",
    "        if line == '\\n':\n",
    "            tech_test['test']['tokens'].append(tokens)\n",
    "            tech_test['test']['tags'].append(tags)\n",
    "            tokens = []\n",
    "            tags = []\n",
    "        else:\n",
    "            if line.split(' ')[0] != '':\n",
    "                tokens.append(line.split(' ')[0])\n",
    "                tag = line.split(' ')[1][:-1]\n",
    "                if tag[:1] == 'E':\n",
    "                    tag = 'I'+tag[1:]\n",
    "                elif tag[:1] == 'S':\n",
    "                    tag = 'B'+tag[1:]\n",
    "                tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "for i,token in enumerate(tech_test['test']['tokens']):\n",
    "    tech_test['test']['emb'].append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save pickle\n",
    "with open(\"../data/ner/tech_test.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(tech_test, fw)\n",
    "\n",
    "# ## Load pickle\n",
    "# with open(\"../data/ner/tech_test.pickle\",\"rb\") as fr:\n",
    "#     tech_test = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Householder Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "B-PER\n",
      "I-PER\n",
      "B-ORG\n",
      "I-ORG\n",
      "B-LOC\n",
      "I-LOC\n",
      "B-MISC\n",
      "I-MISC\n"
     ]
    }
   ],
   "source": [
    "test_features_ht = {}\n",
    "train_data = conll['train']\n",
    "test_data = tech_test['test']\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "## target all subtokens\n",
    "train_all_subtokens = []\n",
    "train_all_tokens = []\n",
    "train_all_tags = []\n",
    "train_subtoken_map = []\n",
    "subtoken_length = 0\n",
    "for sent_idx, tokens in enumerate(train_data['tokens']):\n",
    "    train_all_tokens += tokens\n",
    "    train_all_tags += train_data['tags'][sent_idx]\n",
    "    subtoken_length += 1\n",
    "    sent_subtoken = []\n",
    "    for token in tokens:\n",
    "        subtokens = tokenizer([token], return_tensors=\"pt\",is_split_into_words=True)[\"input_ids\"][0]\n",
    "        subtokens = tokenizer.convert_ids_to_tokens(subtokens)\n",
    "        train_subtoken_map.append(subtoken_length)\n",
    "        subtoken_length += len(subtokens[1:-1])\n",
    "        sent_subtoken += subtokens[1:-1]\n",
    "    subtoken_length += 1\n",
    "    train_all_subtokens += ['[CLS]'] + sent_subtoken + ['[SEP]']\n",
    "\n",
    "## target all emb\n",
    "train_all_emb = [token_emb for sent in train_data['emb'] for token_emb in sent]\n",
    "\n",
    "\n",
    "    \n",
    "## target all subtokens\n",
    "test_all_subtokens = []\n",
    "test_all_tokens = []\n",
    "test_all_tags = []\n",
    "test_subtoken_map = []\n",
    "subtoken_length = 0\n",
    "for sent_idx, tokens in enumerate(test_data['tokens']):\n",
    "    test_all_tokens += tokens\n",
    "    test_all_tags += test_data['tags'][sent_idx]\n",
    "    subtoken_length += 1\n",
    "    sent_subtoken = []\n",
    "    for token in tokens:\n",
    "        subtokens = tokenizer([token], return_tensors=\"pt\",is_split_into_words=True)[\"input_ids\"][0]\n",
    "        subtokens = tokenizer.convert_ids_to_tokens(subtokens)\n",
    "        test_subtoken_map.append(subtoken_length)\n",
    "        subtoken_length += len(subtokens[1:-1])\n",
    "        sent_subtoken += subtokens[1:-1]\n",
    "    subtoken_length += 1\n",
    "    test_all_subtokens += ['[CLS]'] + sent_subtoken + ['[SEP]']\n",
    "\n",
    "## target all emb\n",
    "test_all_emb = [token_emb for sent in test_data['emb'] for token_emb in sent]\n",
    "  \n",
    "    \n",
    "# divide label by label\n",
    "# map between token and subtoken embedding\n",
    "for target_label in label_list:\n",
    "    # divide and map source data\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for tok_idx, tag in enumerate(train_all_tokens):\n",
    "        map_idx = train_subtoken_map[tok_idx]\n",
    "        emb = train_all_emb[map_idx]\n",
    "        tag = train_all_tags[tok_idx]\n",
    "        train_features.append(emb)\n",
    "        if tag == target_label:\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            train_labels.append(0)\n",
    " \n",
    "    # divide and map target data\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for tok_idx, tag in enumerate(test_all_tokens):\n",
    "        map_idx = test_subtoken_map[tok_idx]\n",
    "        emb = test_all_emb[map_idx]\n",
    "        tag = test_all_tags[tok_idx]\n",
    "        test_features.append(emb)\n",
    "        if tag == target_label:\n",
    "            test_labels.append(1)\n",
    "        else:\n",
    "            test_labels.append(0)\n",
    "\n",
    "    # transform to numpy\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # householder transformation\n",
    "    test_features_ht[target_label] = ht_lr(train_features, train_labels, test_features)\n",
    "    print(target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203621\n",
      "203621\n",
      "54070\n",
      "54070\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(len(train_labels))\n",
    "print(len(test_features))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save pickle\n",
    "with open(\"../data/ner/test_features_ht.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(test_features_ht, fw)\n",
    "\n",
    "# ## Load pickle\n",
    "# with open(\"../data/ner/test_features_ht.pickle\",\"rb\") as fr:\n",
    "#     test_features_ht = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# with ht\n",
    "prediction_ht = []\n",
    "for index in range(len(test_features_ht['O'])):\n",
    "    tag_prob_layer = []\n",
    "    for tag_index, target_label in enumerate(label_list):\n",
    "        token_emb = test_features_ht[target_label][index] # get ht-ed token embedding\n",
    "        token_emb = torch.from_numpy(token_emb).float() # make it as torch\n",
    "        logit = model.classifier(token_emb) # pass emb into finetuned classifier to get logit\n",
    "        sm = torch.nn.Softmax(dim = 0) # pass logit into softmax layer\n",
    "        softmax = sm(logit)\n",
    "        tag_prob_layer.append(softmax.tolist()[tag_index]) # only take probability of target tag\n",
    "#         tag_prob_layer.append(logit.tolist()[tag_index]) # only take logit of target tag\n",
    "#     tag_prob_layer = torch.from_numpy(np.array(tag_prob_layer)).float() # transform to tensor\n",
    "#     sm = torch.nn.Softmax(dim = 0)\n",
    "#     output_layer = sm(tag_prob_layer) # pass logits to softmax\n",
    "#     output_layer = output_layer.tolist()\n",
    "#     predict_tag_index = np.argmax(output_layer)\n",
    "    predict_tag_index = np.argmax(tag_prob_layer)\n",
    "    predict_tag = label_list[predict_tag_index]\n",
    "    prediction_ht.append(predict_tag)\n",
    "    if index%10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in test_all_tags if x in ['I-LOC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.02      0.01      0.02       489\n",
      "        MISC       0.09      0.15      0.11       365\n",
      "         ORG       0.22      0.48      0.30       873\n",
      "         PER       0.01      0.01      0.01      1094\n",
      "\n",
      "   micro avg       0.13      0.17      0.15      2821\n",
      "   macro avg       0.08      0.16      0.11      2821\n",
      "weighted avg       0.09      0.17      0.11      2821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([test_all_tags], [prediction_ht]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# without ht\n",
    "tech_test_emb = [test_all_emb[i] for i in test_subtoken_map]\n",
    "prediction = []\n",
    "for index in range(len(tech_test_emb)):\n",
    "    token_emb = tech_test_emb[index] # get ht-ed token embedding\n",
    "    token_emb = torch.from_numpy(token_emb).float() # make it as torch\n",
    "    logit = model.classifier(token_emb) # pass emb into finetuned classifier to get logit\n",
    "    sm = torch.nn.Softmax(dim = 0) # pass logit into softmax layer\n",
    "    softmax = sm(logit)\n",
    "    predict_tag_index = np.argmax(softmax.tolist())\n",
    "    predict_tag = label_list[predict_tag_index]\n",
    "    prediction.append(predict_tag)\n",
    "    if index%10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.01      0.02      0.01       489\n",
      "        MISC       0.10      0.17      0.12       365\n",
      "         ORG       0.01      0.02      0.01       873\n",
      "         PER       0.00      0.00      0.00      1094\n",
      "\n",
      "   micro avg       0.03      0.03      0.03      2821\n",
      "   macro avg       0.03      0.05      0.04      2821\n",
      "weighted avg       0.02      0.03      0.02      2821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([test_all_tags], [prediction]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
