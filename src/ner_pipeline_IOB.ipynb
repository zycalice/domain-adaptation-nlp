{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text,tokenizer,model,is_split_into_words=True):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", is_split_into_words=is_split_into_words)\n",
    "    labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(**inputs, labels=labels)\n",
    "    output = np.array(outputs.hidden_states[12][0].tolist())\n",
    "    return output\n",
    "\n",
    "    # back to torch tensor:\n",
    "    # torch.from_numpy(output).float()\n",
    "\n",
    "def ht_sm(train_features, train_labels, test_features, classifier, label_idx):\n",
    "    # aligning target domain to source domain\n",
    "    sm = torch.nn.Softmax(dim = 0)\n",
    "    y_prob = [sm(classifier(torch.from_numpy(test_features[i]).float())).tolist()[label_idx] for i in range(len(test_features))]\n",
    "    y_prob = [(i, val) for i, val in enumerate(y_prob)]\n",
    "    y_prob = sorted(y_prob, key=lambda x: x[1])\n",
    "    y_prob_P = [val for val in y_prob if val[1]>0.90]\n",
    "    y_prob_N = y_prob[:int(len(y_prob_P))]\n",
    "\n",
    "    sourcePos = [val for i, val in enumerate(train_features) if train_labels[i] == 1]\n",
    "    sourceNeg = [val for i, val in enumerate(train_features) if train_labels[i] == 0]\n",
    "    targetPos = [test_features[val[0]] for val in y_prob_P]\n",
    "    targetNeg = [test_features[val[0]] for val in y_prob_N]\n",
    "    v = np.mean(sourcePos, axis=0) - np.mean(sourceNeg, axis=0)\n",
    "    u = np.mean(targetPos, axis=0) - np.mean(targetNeg, axis=0)\n",
    "    c1 = np.mean(test_features, axis=0)\n",
    "    c2 = np.mean(np.concatenate([sourcePos, sourceNeg], axis=0), axis=0)\n",
    "\n",
    "    test_features = hh_lr(u, v, c1, c2, test_features)\n",
    "    return test_features\n",
    "    \n",
    "\n",
    "\n",
    "def ht_lr(train_features, train_labels, test_features):\n",
    "    # aligning target domain to source domain\n",
    "    lr_clf = LogisticRegression(max_iter = 10000)\n",
    "    lr_clf.fit(train_features, train_labels)\n",
    "    y_pred = lr_clf.predict(test_features)\n",
    "    y_prob = lr_clf.predict_proba(test_features)[:, 0]\n",
    "    y_prob = [(i, val, y_pred[i]) for i, val in enumerate(y_prob)]\n",
    "    y_prob = sorted(y_prob, key=lambda x: x[1])\n",
    "    y_prob_P = y_prob[:int(len(test_features) / 10)]\n",
    "    y_prob_N = y_prob[-int(len(test_features) / 10):]\n",
    "\n",
    "    sourcePos = [val for i, val in enumerate(train_features) if train_labels[i] == 1]\n",
    "    sourceNeg = [val for i, val in enumerate(train_features) if train_labels[i] == 0]\n",
    "    targetPos = [test_features[val[0]] for val in y_prob_P]\n",
    "    targetNeg = [test_features[val[0]] for val in y_prob_N]\n",
    "    v = np.mean(sourcePos, axis=0) - np.mean(sourceNeg, axis=0)\n",
    "    u = np.mean(targetPos, axis=0) - np.mean(targetNeg, axis=0)\n",
    "    c1 = np.mean(test_features, axis=0)\n",
    "    c2 = np.mean(np.concatenate([sourcePos, sourceNeg], axis=0), axis=0)\n",
    "\n",
    "    test_features = hh_lr(u, v, c1, c2, test_features)\n",
    "    return test_features\n",
    "\n",
    "\n",
    "def hh_lr(u, v, c1, c2, points):\n",
    "    # household transformation\n",
    "    u_mag = np.linalg.norm(u)\n",
    "    u_unit = u / u_mag\n",
    "\n",
    "    v_mag = np.linalg.norm(v)\n",
    "    v_unit = v / v_mag\n",
    "\n",
    "    # Scaling so pos-neg vectors have the same magnitude\n",
    "    scaled_points = points * v_mag / u_mag\n",
    "    scaled_c1 = c1 * v_mag / u_mag\n",
    "\n",
    "    # gettinng dimension of vector space\n",
    "    k = len(c2)\n",
    "\n",
    "    # calculating isometric linear transformation: householder transformation\n",
    "    A = np.eye(k) - (2 * (np.outer(u_unit - v_unit, u_unit - v_unit) / np.inner(u_unit - v_unit, u_unit - v_unit)))\n",
    "\n",
    "    # applying isometric transformation\n",
    "    points_after_isometric = scaled_points @ A.T\n",
    "    c1_after_isometric = scaled_c1 @ A.T\n",
    "\n",
    "    # translation\n",
    "    points_after_translation = points_after_isometric + (c2 - c1_after_isometric)\n",
    "\n",
    "    return points_after_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoNLL2003 pretrained BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'European', 'score': 0.9995400309562683, 'entity': 'B-ORG', 'index': 1, 'start': 0, 'end': 8}, {'word': 'Union', 'score': 0.9992778897285461, 'entity': 'I-ORG', 'index': 2, 'start': 9, 'end': 14}, {'word': 'Paris', 'score': 0.9994699358940125, 'entity': 'B-LOC', 'index': 4, 'start': 16, 'end': 21}, {'word': 'Berlin', 'score': 0.9994154572486877, 'entity': 'B-LOC', 'index': 6, 'start': 23, 'end': 29}]\n"
     ]
    }
   ],
   "source": [
    "# BERT example\n",
    "example = \"European Union, Paris, Berlin\"\n",
    "\n",
    "inputs = tokenizer(example, return_tensors=\"pt\",is_split_into_words=False)\n",
    "labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits \n",
    "# equal to model.classifier(outputs.hidden_states[12]) \n",
    "# equal to model.classifier(torch.from_numpy(get_embedding(\"Hello, my dog is cute\",tokenizer,model,is_split_into_words=False)).float()) \n",
    "\n",
    "\n",
    "#==== ner model ====\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'European', 'Union', ',', 'Paris', ',', 'Berlin', '[SEP]']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (C:\\Users\\zhw027\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    }
   ],
   "source": [
    "# load CoNLL2003\n",
    "datasets = load_dataset(\"conll2003\")\n",
    "label_list = [\"O\",'B-MISC', 'I-MISC','B-PER', 'I-PER','B-ORG', 'I-ORG','B-LOC', 'I-LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'id': '0',\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_tags_train = [[label_list[i] for i in dict['ner_tags']] for dict in datasets[\"train\"]]\n",
    "conll_tags_val = [[label_list[i] for i in dict['ner_tags']] for dict in datasets[\"validation\"]]\n",
    "conll_tags_test = [[label_list[i] for i in dict['ner_tags']] for dict in datasets[\"test\"]]\n",
    "\n",
    "conll_tokens_train = [dict['tokens'] for dict in datasets[\"train\"]]\n",
    "conll_tokens_val = [dict['tokens'] for dict in datasets[\"validation\"]]\n",
    "conll_tokens_test = [dict['tokens'] for dict in datasets[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n"
     ]
    }
   ],
   "source": [
    "conll_emb_train = []\n",
    "for i,token in enumerate(conll_tokens_train):\n",
    "    conll_emb_train.append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "conll_emb_val = []\n",
    "for i,token in enumerate(conll_tokens_val):\n",
    "    conll_emb_val.append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "conll_emb_test = []\n",
    "for i,token in enumerate(conll_tokens_test):\n",
    "    conll_emb_test.append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll = {}\n",
    "conll['train'] = {}\n",
    "conll['train']['tokens'] = conll_tokens_train\n",
    "conll['train']['tags'] = conll_tags_train\n",
    "conll['train']['emb'] = conll_emb_train\n",
    "conll['val'] = {}\n",
    "conll['val']['tokens'] = conll_tokens_val\n",
    "conll['val']['tags'] = conll_tags_val\n",
    "conll['val']['emb'] = conll_emb_val\n",
    "conll['test'] = {}\n",
    "conll['test']['tokens'] = conll_tokens_test\n",
    "conll['test']['tags'] = conll_tags_test\n",
    "conll['test']['emb'] = conll_emb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save pickle\n",
    "# with open(\"../data/ner/CoNLL2003_IOB.pickle\",\"wb\") as fw:\n",
    "#     pickle.dump(conll, fw)\n",
    "\n",
    "## Load pickle\n",
    "with open(\"../data/ner/CoNLL2003_IOB.pickle\",\"rb\") as fr:\n",
    "    conll = pickle.load(fr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9986e-01, 3.6812e-05, 2.4579e-05, 9.2055e-06, 8.1857e-06,\n",
       "          2.2269e-05, 1.4744e-05, 6.9506e-06, 1.3782e-05],\n",
       "         [1.4827e-04, 2.5760e-04, 3.9912e-05, 8.2197e-05, 1.5342e-05,\n",
       "          9.9934e-01, 3.7962e-05, 6.1841e-05, 1.5613e-05],\n",
       "         [9.9995e-01, 8.1573e-06, 7.9834e-06, 2.9079e-06, 2.6201e-06,\n",
       "          6.7544e-06, 1.2999e-05, 1.9078e-06, 4.5467e-06],\n",
       "         [5.0466e-05, 9.9968e-01, 1.6745e-04, 1.7678e-05, 2.0535e-05,\n",
       "          2.9858e-05, 1.1429e-05, 1.3439e-05, 1.0506e-05],\n",
       "         [9.9995e-01, 7.1225e-06, 1.3930e-05, 3.3021e-06, 2.7692e-06,\n",
       "          3.7986e-06, 7.8546e-06, 1.8355e-06, 5.0073e-06],\n",
       "         [9.9997e-01, 5.1965e-06, 5.2533e-06, 2.1644e-06, 1.9781e-06,\n",
       "          2.3487e-06, 4.4365e-06, 1.4817e-06, 3.1004e-06],\n",
       "         [9.9997e-01, 6.6605e-06, 5.5180e-06, 2.1587e-06, 1.9227e-06,\n",
       "          2.9116e-06, 4.4655e-06, 1.4905e-06, 3.5648e-06],\n",
       "         [4.0992e-05, 9.9961e-01, 2.3095e-04, 2.0966e-05, 1.9953e-05,\n",
       "          4.0297e-05, 9.3106e-06, 1.3606e-05, 1.0496e-05],\n",
       "         [9.9993e-01, 1.3283e-05, 1.8737e-05, 5.5124e-06, 3.1962e-06,\n",
       "          5.0375e-06, 1.1361e-05, 3.4846e-06, 8.7945e-06],\n",
       "         [9.9970e-01, 4.9790e-05, 1.0490e-04, 1.4098e-05, 1.2104e-05,\n",
       "          1.9068e-05, 4.4024e-05, 9.8471e-06, 4.6963e-05],\n",
       "         [9.9996e-01, 6.0044e-06, 8.1548e-06, 2.9201e-06, 2.5268e-06,\n",
       "          3.7676e-06, 6.8667e-06, 1.6232e-06, 4.7161e-06],\n",
       "         [9.8452e-01, 1.1885e-02, 1.0722e-03, 8.5635e-05, 1.0724e-04,\n",
       "          1.0800e-03, 6.4125e-04, 3.8008e-04, 2.3284e-04]]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of transforming ndnumpy array to softmax\n",
    "sm(model.classifier(torch.reshape(torch.from_numpy(conll['train']['emb'][0]).float(), (1, len(conll['train']['emb'][0]), 768))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4827e-04, 2.5760e-04, 3.9912e-05, 8.2197e-05, 1.5342e-05,\n",
       "          9.9934e-01, 3.7962e-05, 6.1841e-05, 1.5613e-05]]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of transforming ndnumpy array to softmax, but only extracting one token\n",
    "sm(model.classifier(torch.reshape(torch.from_numpy(conll['train']['emb'][0][1]).float(), (1, 1, 768))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load tech_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300677"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([y for x in conll['train']['emb'] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_test = {}\n",
    "tech_test['test'] = {}\n",
    "tech_test['test']['tokens'] = []\n",
    "tech_test['test']['tags'] = []\n",
    "tech_test['test']['emb'] = []\n",
    "\n",
    "with open('../data/ner/tech_test.txt', 'r') as f:\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for line in f.readlines():\n",
    "        if line == '\\n':\n",
    "            tech_test['test']['tokens'].append(tokens)\n",
    "            tech_test['test']['tags'].append(tags)\n",
    "            tokens = []\n",
    "            tags = []\n",
    "        else:\n",
    "            if line.split(' ')[0] != '':\n",
    "                tokens.append(line.split(' ')[0])\n",
    "                tag = line.split(' ')[1][:-1]\n",
    "                if tag[:1] == 'E':\n",
    "                    tag = 'I'+tag[1:]\n",
    "                elif tag[:1] == 'S':\n",
    "                    tag = 'B'+tag[1:]\n",
    "                tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "for i,token in enumerate(tech_test['test']['tokens']):\n",
    "    tech_test['test']['emb'].append(get_embedding(token,tokenizer,model))\n",
    "    if i%100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save pickle\n",
    "# with open(\"../data/ner/tech_test_IOB.pickle\",\"wb\") as fw:\n",
    "#     pickle.dump(tech_test, fw)\n",
    "\n",
    "## Load pickle\n",
    "with open(\"../data/ner/tech_test_IOB.pickle\",\"rb\") as fr:\n",
    "    tech_test = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Householder Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word-token mapping\n",
    "\n",
    "train_data = conll['train']\n",
    "val_data = conll['test']\n",
    "test_data = tech_test['test']\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "## train all subtokens\n",
    "train_all_subtokens = []\n",
    "train_all_tokens = []\n",
    "train_all_tags = []\n",
    "train_subtoken_map = []\n",
    "subtoken_length = 0\n",
    "for sent_idx, tokens in enumerate(train_data['tokens']):\n",
    "    train_all_tokens += tokens\n",
    "    train_all_tags += train_data['tags'][sent_idx]\n",
    "    subtoken_length += 1\n",
    "    sent_subtoken = []\n",
    "    for token in tokens:\n",
    "        subtokens = tokenizer([token], return_tensors=\"pt\",is_split_into_words=True)[\"input_ids\"][0]\n",
    "        subtokens = tokenizer.convert_ids_to_tokens(subtokens)\n",
    "        train_subtoken_map.append(subtoken_length)\n",
    "        subtoken_length += len(subtokens[1:-1])\n",
    "        sent_subtoken += subtokens[1:-1]\n",
    "    subtoken_length += 1\n",
    "    train_all_subtokens += ['[CLS]'] + sent_subtoken + ['[SEP]']\n",
    "\n",
    "## train all emb\n",
    "train_all_emb = [token_emb for sent in train_data['emb'] for token_emb in sent]\n",
    "\n",
    "# preprocessing\n",
    "## val all subtokens\n",
    "val_all_subtokens = []\n",
    "val_all_tokens = []\n",
    "val_all_tags = []\n",
    "val_subtoken_map = []\n",
    "subtoken_length = 0\n",
    "for sent_idx, tokens in enumerate(val_data['tokens']):\n",
    "    val_all_tokens += tokens\n",
    "    val_all_tags += val_data['tags'][sent_idx]\n",
    "    subtoken_length += 1\n",
    "    sent_subtoken = []\n",
    "    for token in tokens:\n",
    "        subtokens = tokenizer([token], return_tensors=\"pt\",is_split_into_words=True)[\"input_ids\"][0]\n",
    "        subtokens = tokenizer.convert_ids_to_tokens(subtokens)\n",
    "        val_subtoken_map.append(subtoken_length)\n",
    "        subtoken_length += len(subtokens[1:-1])\n",
    "        sent_subtoken += subtokens[1:-1]\n",
    "    subtoken_length += 1\n",
    "    val_all_subtokens += ['[CLS]'] + sent_subtoken + ['[SEP]']\n",
    "\n",
    "## val all emb\n",
    "val_all_emb = [token_emb for sent in val_data['emb'] for token_emb in sent]\n",
    "\n",
    "    \n",
    "## test all subtokens\n",
    "test_all_subtokens = []\n",
    "test_all_tokens = []\n",
    "test_all_tags = []\n",
    "test_subtoken_map = []\n",
    "subtoken_length = 0\n",
    "for sent_idx, tokens in enumerate(test_data['tokens']):\n",
    "    test_all_tokens += tokens\n",
    "    test_all_tags += test_data['tags'][sent_idx]\n",
    "    subtoken_length += 1\n",
    "    sent_subtoken = []\n",
    "    for token in tokens:\n",
    "        subtokens = tokenizer([token], return_tensors=\"pt\",is_split_into_words=True)[\"input_ids\"][0]\n",
    "        subtokens = tokenizer.convert_ids_to_tokens(subtokens)\n",
    "        test_subtoken_map.append(subtoken_length)\n",
    "        subtoken_length += len(subtokens[1:-1])\n",
    "        sent_subtoken += subtokens[1:-1]\n",
    "    subtoken_length += 1\n",
    "    test_all_subtokens += ['[CLS]'] + sent_subtoken + ['[SEP]']\n",
    "\n",
    "## test all emb\n",
    "test_all_emb = [token_emb for sent in test_data['emb'] for token_emb in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "B-MISC\n",
      "I-MISC\n",
      "B-PER\n",
      "I-PER\n",
      "B-ORG\n",
      "I-ORG\n",
      "B-LOC\n",
      "I-LOC\n"
     ]
    }
   ],
   "source": [
    "# HT\n",
    "\n",
    "test_features_ht = {}\n",
    "\n",
    "\n",
    "# divide label by label\n",
    "# map between token and subtoken embedding\n",
    "for label_idx, target_label in enumerate(label_list):\n",
    "    # divide and map source data\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for tok_idx, tag in enumerate(train_all_tokens):\n",
    "        map_idx = train_subtoken_map[tok_idx]\n",
    "        emb = train_all_emb[map_idx]\n",
    "        tag = train_all_tags[tok_idx]\n",
    "        train_features.append(emb)\n",
    "        if tag == target_label:\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            train_labels.append(0)\n",
    " \n",
    "    # divide and map target data\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for tok_idx, tag in enumerate(test_all_tokens):\n",
    "        map_idx = test_subtoken_map[tok_idx]\n",
    "        emb = test_all_emb[map_idx]\n",
    "        tag = test_all_tags[tok_idx]\n",
    "        test_features.append(emb)\n",
    "        if tag == target_label:\n",
    "            test_labels.append(1)\n",
    "        else:\n",
    "            test_labels.append(0)\n",
    "\n",
    "    # transform to numpy\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # householder transformation\n",
    "    test_features_ht[target_label] = ht_sm(train_features, train_labels, test_features, model.classifier, label_idx)\n",
    "    print(target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only ht OOV tokens\n",
    "OOV = list(set([token for token in test_all_tokens if token not in train_all_tokens]))\n",
    "for target_label in label_list:\n",
    "    OOV_ht = []\n",
    "    for token_idx, emb in enumerate(test_features_ht[target_label]):\n",
    "        if test_all_tokens[token_idx] in OOV:\n",
    "            OOV_ht.append(emb)\n",
    "        else:\n",
    "            OOV_ht.append(test_features[token_idx])\n",
    "    OOV_ht = np.array(OOV_ht)\n",
    "    test_features_ht[target_label] = OOV_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203621\n",
      "203621\n",
      "54070\n",
      "54070\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(len(train_labels))\n",
    "print(len(test_features))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save pickle\n",
    "with open(\"../data/ner/test_features_ht_IOB.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(test_features_ht, fw)\n",
    "\n",
    "# ## Load pickle\n",
    "# with open(\"../data/ner/test_features_ht_IOB.pickle\",\"rb\") as fr:\n",
    "#     test_features_ht = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-MISC       0.38      0.49      0.43       365\n",
      "      I-MISC       0.25      0.50      0.34       132\n",
      "       B-PER       0.93      0.93      0.93      1091\n",
      "       I-PER       0.96      0.98      0.97       568\n",
      "       B-ORG       0.69      0.83      0.75       872\n",
      "       I-ORG       0.54      0.77      0.63       476\n",
      "       B-LOC       0.65      0.85      0.74       489\n",
      "       I-LOC       0.48      0.77      0.59       140\n",
      "\n",
      "   micro avg       0.69      0.83      0.75      4133\n",
      "   macro avg       0.61      0.76      0.67      4133\n",
      "weighted avg       0.72      0.83      0.77      4133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with ht\n",
    "prediction_ht = []\n",
    "for index in range(len(test_features_ht['O'])):\n",
    "    tag_prob_layer = []\n",
    "    for tag_index, target_label in enumerate(label_list):\n",
    "        token_emb = test_features_ht[target_label][index] # get ht-ed token embedding\n",
    "        token_emb = torch.from_numpy(token_emb).float() # make it as torch\n",
    "        logit = model.classifier(token_emb) # pass emb into finetuned classifier to get logit\n",
    "        sm = torch.nn.Softmax(dim = 0) # pass logit into softmax layer\n",
    "        softmax = sm(logit)\n",
    "        tag_prob_layer.append(softmax.tolist()[tag_index]) # only take probability of target tag\n",
    "#         tag_prob_layer.append(logit.tolist()[tag_index]) # only take logit of target tag\n",
    "#     tag_prob_layer = torch.from_numpy(np.array(tag_prob_layer)).float() # transform to tensor\n",
    "#     sm = torch.nn.Softmax(dim = 0)\n",
    "#     output_layer = sm(tag_prob_layer) # pass logits to softmax\n",
    "#     output_layer = output_layer.tolist()\n",
    "#     predict_tag_index = np.argmax(output_layer)\n",
    "    predict_tag_index = np.argmax(tag_prob_layer)\n",
    "    predict_tag = label_list[predict_tag_index]\n",
    "    prediction_ht.append(predict_tag)\n",
    "print(classification_report(y_true=test_all_tags, y_pred=prediction_ht, labels=[label for label in label_list if label != \"O\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.60      0.80      0.69       489\n",
      "        MISC       0.34      0.47      0.40       365\n",
      "         ORG       0.64      0.79      0.71       873\n",
      "         PER       0.93      0.93      0.93      1094\n",
      "\n",
      "   micro avg       0.68      0.80      0.74      2821\n",
      "   macro avg       0.63      0.75      0.68      2821\n",
      "weighted avg       0.71      0.80      0.75      2821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([test_all_tags], [prediction_ht]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without ht\n",
    "tech_test_emb = [test_all_emb[i] for i in test_subtoken_map]\n",
    "prediction = []\n",
    "for index in range(len(tech_test_emb)):\n",
    "    token_emb = tech_test_emb[index] # get ht-ed token embedding\n",
    "    token_emb = torch.from_numpy(token_emb).float() # make it as torch\n",
    "    logit = model.classifier(token_emb) # pass emb into finetuned classifier to get logit\n",
    "    sm = torch.nn.Softmax(dim = 0) # pass logit into softmax layer\n",
    "    softmax = sm(logit)\n",
    "    predict_tag_index = np.argmax(softmax.tolist())\n",
    "    predict_tag = label_list[predict_tag_index]\n",
    "    prediction.append(predict_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.60      0.80      0.69       489\n",
      "        MISC       0.34      0.47      0.40       365\n",
      "         ORG       0.64      0.78      0.70       873\n",
      "         PER       0.93      0.92      0.92      1094\n",
      "\n",
      "   micro avg       0.68      0.80      0.74      2821\n",
      "   macro avg       0.63      0.75      0.68      2821\n",
      "weighted avg       0.71      0.80      0.75      2821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([test_all_tags], [prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-MISC       0.38      0.49      0.43       365\n",
      "      I-MISC       0.26      0.50      0.34       132\n",
      "       B-PER       0.93      0.93      0.93      1091\n",
      "       I-PER       0.96      0.98      0.97       568\n",
      "       B-ORG       0.68      0.82      0.75       872\n",
      "       I-ORG       0.53      0.77      0.63       476\n",
      "       B-LOC       0.65      0.85      0.74       489\n",
      "       I-LOC       0.48      0.76      0.59       140\n",
      "\n",
      "   micro avg       0.69      0.83      0.75      4133\n",
      "   macro avg       0.61      0.76      0.67      4133\n",
      "weighted avg       0.72      0.83      0.76      4133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=test_all_tags, y_pred=prediction, labels=[label for label in label_list if label != \"O\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# conll test\n",
    "conll_val_emb = [val_all_emb[i] for i in val_subtoken_map]\n",
    "prediction = []\n",
    "for index in range(len(conll_val_emb)):\n",
    "    token_emb = conll_val_emb[index] # get ht-ed token embedding\n",
    "    token_emb = torch.from_numpy(token_emb).float() # make it as torch\n",
    "    logit = model.classifier(token_emb) # pass emb into finetuned classifier to get logit\n",
    "    sm = torch.nn.Softmax(dim = 0) # pass logit into softmax layer\n",
    "    softmax = sm(logit)\n",
    "    predict_tag_index = np.argmax(softmax.tolist())\n",
    "    predict_tag = label_list[predict_tag_index]\n",
    "    prediction.append(predict_tag)\n",
    "    if index%10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       1.00      0.99      0.99     38323\n",
      "      B-MISC       0.83      0.85      0.84       702\n",
      "      I-MISC       0.65      0.76      0.70       216\n",
      "       B-PER       0.96      0.96      0.96      1617\n",
      "       I-PER       0.99      0.99      0.99      1156\n",
      "       B-ORG       0.91      0.93      0.92      1661\n",
      "       I-ORG       0.89      0.92      0.91       835\n",
      "       B-LOC       0.94      0.93      0.94      1668\n",
      "       I-LOC       0.88      0.90      0.89       257\n",
      "\n",
      "    accuracy                           0.98     46435\n",
      "   macro avg       0.89      0.92      0.90     46435\n",
      "weighted avg       0.98      0.98      0.98     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=val_all_tags, y_pred=prediction, labels=label_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
